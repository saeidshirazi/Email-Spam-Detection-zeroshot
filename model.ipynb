{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-extractive-summarizer in ./.venv/lib/python3.12/site-packages (0.10.1)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (from bert-extractive-summarizer) (4.47.0)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (from bert-extractive-summarizer) (1.5.2)\n",
      "Requirement already satisfied: spacy in ./.venv/lib/python3.12/site-packages (from bert-extractive-summarizer) (3.8.3)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.12/site-packages (from scikit-learn->bert-extractive-summarizer) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn->bert-extractive-summarizer) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn->bert-extractive-summarizer) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn->bert-extractive-summarizer) (3.5.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.12/site-packages (from spacy->bert-extractive-summarizer) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.12/site-packages (from spacy->bert-extractive-summarizer) (1.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.12/site-packages (from spacy->bert-extractive-summarizer) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.12/site-packages (from spacy->bert-extractive-summarizer) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in ./.venv/lib/python3.12/site-packages (from spacy->bert-extractive-summarizer) (8.3.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.12/site-packages (from spacy->bert-extractive-summarizer) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.venv/lib/python3.12/site-packages (from spacy->bert-extractive-summarizer) (2.5.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.12/site-packages (from spacy->bert-extractive-summarizer) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./.venv/lib/python3.12/site-packages (from spacy->bert-extractive-summarizer) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from spacy->bert-extractive-summarizer) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.venv/lib/python3.12/site-packages (from spacy->bert-extractive-summarizer) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from spacy->bert-extractive-summarizer) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.venv/lib/python3.12/site-packages (from spacy->bert-extractive-summarizer) (2.10.3)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from spacy->bert-extractive-summarizer) (3.1.4)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from spacy->bert-extractive-summarizer) (75.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from spacy->bert-extractive-summarizer) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.venv/lib/python3.12/site-packages (from spacy->bert-extractive-summarizer) (3.5.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from transformers->bert-extractive-summarizer) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in ./.venv/lib/python3.12/site-packages (from transformers->bert-extractive-summarizer) (0.26.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers->bert-extractive-summarizer) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers->bert-extractive-summarizer) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.12/site-packages (from transformers->bert-extractive-summarizer) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.12/site-packages (from transformers->bert-extractive-summarizer) (0.4.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers->bert-extractive-summarizer) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers->bert-extractive-summarizer) (4.12.2)\n",
      "Requirement already satisfied: language-data>=1.2 in ./.venv/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy->bert-extractive-summarizer) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->bert-extractive-summarizer) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->bert-extractive-summarizer) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.1.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.0->spacy->bert-extractive-summarizer) (1.0.2)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.0->spacy->bert-extractive-summarizer) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy->bert-extractive-summarizer) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy->bert-extractive-summarizer) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->spacy->bert-extractive-summarizer) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in ./.venv/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->bert-extractive-summarizer) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (2.18.0)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->bert-extractive-summarizer) (1.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bert-extractive-summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the cleaned dataset from CSV\n",
    "cleaned_dataset_path = 'cleaned_spam.csv'\n",
    "df = pd.read_csv(cleaned_dataset_path)\n",
    "print(\"Cleaned dataset loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "      <th>text_length</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>subject enron methanol meter follow note gave ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>subject hpl nom january see attached file hpln...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>2524</td>\n",
       "      <td>subject neon retreat ho ho ho around wonderful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "      <td>414</td>\n",
       "      <td>subject photoshop windows office cheap main tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "      <td>336</td>\n",
       "      <td>subject indian springs deal book teco pvr reve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num  text_length                                       cleaned_text  \n",
       "0          0          327  subject enron methanol meter follow note gave ...  \n",
       "1          0           97  subject hpl nom january see attached file hpln...  \n",
       "2          0         2524  subject neon retreat ho ho ho around wonderful...  \n",
       "3          1          414  subject photoshop windows office cheap main tr...  \n",
       "4          0          336  subject indian springs deal book teco pvr reve...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarizer import Summarizer\n",
    "\n",
    "# Initialize the BERT summarizer\n",
    "bert_summarizer = Summarizer()\n",
    "\n",
    "# Function to summarize text while handling potential errors\n",
    "def summarize_text(text):\n",
    "    try:\n",
    "        # Check if text is string and not empty\n",
    "        if isinstance(text, str) and text.strip():\n",
    "            return bert_summarizer(text, num_sentences=2)  # Adjust number of sentences as needed\n",
    "        return text\n",
    "    except Exception:\n",
    "        return text\n",
    "\n",
    "# Apply summarization to clean_text column\n",
    "df['summarized_text'] = df['cleaned_text'].apply(summarize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "      <th>text_length</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>summarized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>subject enron methanol meter follow note gave ...</td>\n",
       "      <td>subject enron methanol meter follow note gave ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>subject hpl nom january see attached file hpln...</td>\n",
       "      <td>subject hpl nom january see attached file hpln...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>2524</td>\n",
       "      <td>subject neon retreat ho ho ho around wonderful...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "      <td>414</td>\n",
       "      <td>subject photoshop windows office cheap main tr...</td>\n",
       "      <td>subject photoshop windows office cheap main tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "      <td>336</td>\n",
       "      <td>subject indian springs deal book teco pvr reve...</td>\n",
       "      <td>subject indian springs deal book teco pvr reve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num  text_length                                       cleaned_text  \\\n",
       "0          0          327  subject enron methanol meter follow note gave ...   \n",
       "1          0           97  subject hpl nom january see attached file hpln...   \n",
       "2          0         2524  subject neon retreat ho ho ho around wonderful...   \n",
       "3          1          414  subject photoshop windows office cheap main tr...   \n",
       "4          0          336  subject indian springs deal book teco pvr reve...   \n",
       "\n",
       "                                     summarized_text  \n",
       "0  subject enron methanol meter follow note gave ...  \n",
       "1  subject hpl nom january see attached file hpln...  \n",
       "2                                                     \n",
       "3  subject photoshop windows office cheap main tr...  \n",
       "4  subject indian springs deal book teco pvr reve...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject ehronline web address change message intended ehronline users due recent change ehronline url aka web address accessing ehronline needs changed computer change involves adding letter http reference url url accessing ehronline https ehronline enron com change made added url favorite browser\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[5, 'summarized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in 'label': 0\n",
      "Null values in 'predicted_label': 1699\n",
      "Invalid predicted_label rows:\n",
      "       Unnamed: 0 label                                               text  \\\n",
      "2           3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
      "6           2793   ham  Subject: spring savings certificate - take 30 ...   \n",
      "10          4922  spam  Subject: vocable % rnd - word asceticism\\r\\nvc...   \n",
      "15          4791  spam  Subject: underpriced issue with high return on...   \n",
      "16          2643   ham  Subject: re : first delivery - wheeler operati...   \n",
      "...          ...   ...                                                ...   \n",
      "5145        3348   ham  Subject: re : epgt\\r\\ngloria , the difference ...   \n",
      "5154        2203   ham  Subject: re : hpl meter # 980074 bammel hpl d ...   \n",
      "5161        4979  spam  Subject: penny stocks are about timing\\r\\nnoma...   \n",
      "5163        1428   ham  Subject: re : meter # : 1266 ; august 2000 / a...   \n",
      "5170        4807  spam  Subject: important online banking alert\\r\\ndea...   \n",
      "\n",
      "      label_num  text_length  \\\n",
      "2             0         2524   \n",
      "6             0         2076   \n",
      "10            1         6922   \n",
      "15            1         9092   \n",
      "16            0         2880   \n",
      "...         ...          ...   \n",
      "5145          0         1247   \n",
      "5154          0         2370   \n",
      "5161          1         4158   \n",
      "5163          0         5549   \n",
      "5170          1         1114   \n",
      "\n",
      "                                           cleaned_text summarized_text  \\\n",
      "2     subject neon retreat ho ho ho around wonderful...                   \n",
      "6     subject spring savings certificate take save u...                   \n",
      "10    subject vocable rnd word asceticism vcsc brand...                   \n",
      "15    subject underpriced issue high return equity s...                   \n",
      "16    subject first delivery wheeler operating vance...                   \n",
      "...                                                 ...             ...   \n",
      "5145  subject epgt gloria difference two pipes july ...                   \n",
      "5154  subject hpl meter bammel hpl p transco daren h...                   \n",
      "5161  subject penny stocks timing nomad internationa...                   \n",
      "5163  subject meter august allocation exception cono...                   \n",
      "5170  subject important online banking alert dear va...                   \n",
      "\n",
      "     predicted_label  \n",
      "2               None  \n",
      "6               None  \n",
      "10              None  \n",
      "15              None  \n",
      "16              None  \n",
      "...              ...  \n",
      "5145            None  \n",
      "5154            None  \n",
      "5161            None  \n",
      "5163            None  \n",
      "5170            None  \n",
      "\n",
      "[1699 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for None or missing values in 'label' or 'predicted_label'\n",
    "print(\"Null values in 'label':\", df['label'].isnull().sum())\n",
    "print(\"Null values in 'predicted_label':\", df['predicted_label'].isnull().sum())\n",
    "\n",
    "# Check rows with None or invalid predicted_label\n",
    "invalid_rows = df[df['predicted_label'].isnull() | (df['predicted_label'] == \"\")]\n",
    "print(\"Invalid predicted_label rows:\\n\", invalid_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None or missing values in 'predicted_label' with \"ham\"\n",
    "df['predicted_label'] = df['predicted_label'].fillna(\"ham\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing or invalid 'predicted_label'\n",
    "df = df[df['predicted_label'].notnull() & (df['predicted_label'] != \"\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'label': ['ham' 'spam']\n",
      "Unique values in 'predicted_label': ['ham' 'spam']\n"
     ]
    }
   ],
   "source": [
    "# Confirm no more invalid values\n",
    "print(\"Unique values in 'label':\", df['label'].unique())\n",
    "print(\"Unique values in 'predicted_label':\", df['predicted_label'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiliaze a zeroshot pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load Zero-Shot Classification pipeline\n",
    "zsl_pipeline = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Define candidate labels\n",
    "candidate_labels = [\"spam\", \"ham\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Zero-SHot Learning to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_with_threshold(text):\n",
    "    try:\n",
    "        if isinstance(text, str) and text.strip():\n",
    "            # Perform zero-shot classification\n",
    "            result = zsl_pipeline(text, candidate_labels=[\"spam\", \"ham\"])\n",
    "            # Check confidence scores\n",
    "            scores = result['scores']\n",
    "            labels = result['labels']\n",
    "            # Ensure the highest confidence score is above a threshold (e.g., 0.5)\n",
    "            if scores[0] > 0.5:\n",
    "                return labels[0]\n",
    "            else:\n",
    "                return \"ham\"  # Default to 'ham' if below threshold\n",
    "        return \"ham\"  # Default to 'ham' for invalid or empty text\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return \"ham\"  # Default fallback for errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the classification to the summarized_text column\n",
    "df['predicted_label'] = df['summarized_text'].apply(classify_text_with_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'label': ['ham' 'spam']\n",
      "Unique values in 'predicted_label': ['ham' 'spam']\n"
     ]
    }
   ],
   "source": [
    "# Inspect unique values in the columns\n",
    "print(\"Unique values in 'label':\", df['label'].unique())\n",
    "print(\"Unique values in 'predicted_label':\", df['predicted_label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.73      0.96      0.83      3672\n",
      "        spam       0.56      0.13      0.21      1499\n",
      "\n",
      "    accuracy                           0.72      5171\n",
      "   macro avg       0.65      0.54      0.52      5171\n",
      "weighted avg       0.68      0.72      0.65      5171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(df['label'], df['predicted_label'])\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(df['label'], df['predicted_label'], target_names=[\"ham\", \"spam\"])\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
